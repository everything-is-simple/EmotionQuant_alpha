# ç”³ä¸‡è¡Œä¸šåˆ†ç±»æŒ‡æ•° - TuShare Proç‰ˆ

**ç‰ˆæœ¬**: v0.01
**åˆ›å»ºæ—¶é—´**: 2024-12-19
**æ›´æ–°æ—¶é—´**: 2025-12-20
**é€‚ç”¨èŒƒå›´**: EmotionQuanté¡¹ç›® ç”³ä¸‡è¡Œä¸šåˆ†æ
**æ•°æ®æº**: TuShare Pro + ç”³ä¸‡å®æºå®˜æ–¹æ ‡å‡†
**ä¼˜å…ˆçº§**: ç”³ä¸‡è¡Œä¸šåˆ†ç±»æƒå¨å‚è€ƒï¼ˆæ’æ˜Ÿç»„æ–‡æ¡£ â­â­â­ï¼‰
**å®šä½**: å‚è€ƒèµ„æ–™ï¼ˆéè®¾è®¡è§„èŒƒï¼‰
**è·¯çº¿å›¾å£å¾„**: Spiral + CPï¼ˆå‘½å `CP-*`ï¼Œä»¥ `Governance/SpiralRoadmap/planA/VORTEX-EVOLUTION-ROADMAP.md` ä¸ºå‡†ï¼‰
**å†²çªå¤„ç†**: è‹¥ä¸ `docs/design/` å†²çªï¼Œä»¥è®¾è®¡æ–‡æ¡£ä¸ºå‡†
**æ•´ç†æ›´æ–°**: 2026-02-05ï¼ˆç³»ç»Ÿé“å¾‹è¡¨è¿°æ›´æ–°ï¼‰

---

## ğŸ†• v3.0 æ›´æ–°è¯´æ˜

### ä¸»è¦æ›´æ–°

- âœ… **2025å¹´æ•°æ®æ ¡å‡†**: åŒæ­¥ç”³ä¸‡å®æº2025å¹´æœ€æ–°åˆ†ç±»è°ƒæ•´

- âœ… **EmotionQuant IRSé€‚é…**: å®Œæ•´æ”¯æŒè¡Œä¸šè½®åŠ¨ç³»ç»Ÿ

- âœ… **æ•°æ®è´¨é‡å¢å¼º**: æ–°å¢æ•°æ®å®Œæ•´æ€§æ ¡éªŒæœºåˆ¶

- âœ… **æ€§èƒ½ä¼˜åŒ–**: ä¼˜åŒ–å¤§æ‰¹é‡è¡Œä¸šæ•°æ®å¤„ç†æ€§èƒ½

- âœ… **é”™è¯¯å¤„ç†å¢å¼º**: å®Œå–„APIè°ƒç”¨å®¹é”™æœºåˆ¶

### ä¸v2.0å¯¹æ¯”

| åŠŸèƒ½ | v2.0 | v3.0 |
| ------ | ------ | ------ |
| ç”³ä¸‡åˆ†ç±»ç‰ˆæœ¬ | SW2021 | SW2021 (2025æ ¡å‡†ç‰ˆ) |
| TuShareé›†æˆ | åŸºç¡€ | å®Œæ•´ï¼ˆå«é‡è¯•æœºåˆ¶ï¼‰ |
| æ•°æ®æ ¡éªŒ | éƒ¨åˆ† | å…¨é¢ï¼ˆ7é¡¹æ£€æŸ¥ï¼‰ |
| EmotionQuanté›†æˆ | MSS+IRS | MSS+IRS+PASå®Œæ•´é›†æˆ |
| åŒ—å‘èµ„é‡‘ | åŸºç¡€ç»Ÿè®¡ | è¯¦ç»†æµå‘åˆ†æ |

---

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

ç”³ä¸‡è¡Œä¸šåˆ†ç±»æŒ‡æ•°æ˜¯ç”±ç”³ä¸‡å®æºç ”ç©¶æ‰€ç¼–åˆ¶çš„ä¸­å›½Aè‚¡å¸‚åœºè¡Œä¸šåˆ†ç±»ä½“ç³»å’ŒæŒ‡æ•°ç³»åˆ—ï¼Œè¢«å¹¿æ³›è®¤ä¸ºæ˜¯ä¸­å›½è‚¡ç¥¨å¸‚åœºæœ€å…·æƒå¨æ€§å’Œå½±å“åŠ›çš„è¡Œä¸šåˆ†ç±»æ ‡å‡†ä¹‹ä¸€ã€‚æœ¬æ–‡æ¡£åŸºäºTuShare Proå®˜æ–¹APIå’Œç”³ä¸‡å®æºæ ‡å‡†ï¼Œä¸“é—¨ä¸ºEmotionQuanté¡¹ç›®å®šåˆ¶ï¼Œ**ä¸¥æ ¼éµå¾ªé¡¹ç›®ç³»ç»Ÿé“å¾‹ï¼ˆé›¶æŠ€æœ¯æŒ‡æ ‡ã€æƒ…ç»ªä¼˜å…ˆã€æœ¬åœ°æ•°æ®ä¼˜å…ˆã€è·¯å¾„ç¡¬ç¼–ç ç»å¯¹ç¦æ­¢ã€Aè‚¡ä¸“å±ï¼‰**ã€‚

### EmotionQuantåˆè§„å£°æ˜ âš ï¸

- âœ… **ä¸¥æ ¼ç¦ç”¨æŠ€æœ¯æŒ‡æ ‡**: æœ¬æ–‡æ¡£ä¸åŒ…å«ä»»ä½•æŠ€æœ¯åˆ†æç›¸å…³å†…å®¹

- âœ… **Aè‚¡ä¸“å±é€‚é…**: åŸºäºç”³ä¸‡2021ç‰ˆå®˜æ–¹æ ‡å‡†ï¼ˆ2025æ ¡å‡†ï¼‰

- âœ… **IRSæ¶æ„ä¸“ç”¨**: ä¸“é—¨ä¸ºIRS(Industry Rotation System)è®¾è®¡

- âœ… **æƒ…ç»ªåˆ†æé©±åŠ¨**: åŸºäºè¡Œä¸šæƒ…ç»ªæ•°æ®è€ŒéæŠ€æœ¯æŒ‡æ ‡

- âœ… **æœ¬åœ°æ•°æ®ä¼˜å…ˆ**: è¡Œä¸šåˆ†ç±»æ•°æ®ä¼˜å…ˆæœ¬åœ°ç¼“å­˜/å­˜å‚¨ï¼Œå¤–éƒ¨æ•°æ®ä»…ç”¨äºç¦»çº¿æ›´æ–°

- âœ… **è·¯å¾„ç¡¬ç¼–ç ç»å¯¹ç¦æ­¢**: è·¯å¾„/å¯†é’¥/é…ç½®é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®æ³¨å…¥

- âœ… **æ’æ˜Ÿç»„æ–‡æ¡£**: çº²é¢†æ€§æ–‡ä»¶ï¼Œç»å¯¹ç¦æ­¢ä¿®æ”¹ â­â­â­

---

## ğŸ¢ åˆ†ç±»ä½“ç³»ç»“æ„ - TuShare Proæ•°æ®è·å–

ç”³ä¸‡è¡Œä¸šåˆ†ç±»é‡‡ç”¨å¤šçº§åˆ†ç±»ç»“æ„ï¼Œæä¾›ä¸åŒç²’åº¦çš„è¡Œä¸šåˆ’åˆ†ã€‚åŸºäºTuShare Pro APIï¼Œå¯ä»¥ç²¾ç¡®è·å–æœ€æ–°çš„å®˜æ–¹åˆ†ç±»æ•°æ®ã€‚

### 2025å¹´æœ€æ–°TuShare Proè¡Œä¸šåˆ†ç±»æ•°æ®è·å–

```python
import tushare as ts
import pandas as pd
from typing import Dict, List, Optional
import time

# åˆå§‹åŒ–API
pro = ts.pro_api('{{TUSHARE_TOKEN}}')

def get_shenwan_industry_structure_v3(retry_count: int = 3) -> Dict:
    """
    è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»ä½“ç³»çš„å®Œæ•´ç»“æ„ (v3.0å¢å¼ºç‰ˆ)
    EmotionQuantä¸“ç”¨ - ä¸ºIRSç³»ç»Ÿæä¾›æ•°æ®æ”¯æŒ

    æ–°å¢åŠŸèƒ½:
    - è‡ªåŠ¨é‡è¯•æœºåˆ¶
    - æ•°æ®å®Œæ•´æ€§éªŒè¯
    - æ€§èƒ½ç›‘æ§
    """

    for attempt in range(retry_count):
        try:
            start_time = time.time()

            # è·å–ä¸€çº§è¡Œä¸šåˆ†ç±»
            df_l1 = pro.index_classify(level='L1', src='SW2021')

            # è·å–äºŒçº§è¡Œä¸šåˆ†ç±»
            df_l2 = pro.index_classify(level='L2', src='SW2021')

            # è·å–ä¸‰çº§è¡Œä¸šåˆ†ç±»
            df_l3 = pro.index_classify(level='L3', src='SW2021')

            elapsed_time = time.time() - start_time

            # v3.0æ–°å¢ï¼šæ•°æ®å®Œæ•´æ€§æ ¡éªŒ
            validation_result = validate_industry_data(df_l1, df_l2, df_l3)

            if not validation_result['is_valid']:
                raise ValueError(f"æ•°æ®å®Œæ•´æ€§æ ¡éªŒå¤±è´¥: {validation_result['message']}")

            return {
                'level_1_industries': df_l1,
                'level_2_industries': df_l2,
                'level_3_industries': df_l3,
                'total_l1': len(df_l1),
                'total_l2': len(df_l2),
                'total_l3': len(df_l3),
                'data_source': 'TuShare Pro + SW2021 (2025æ ¡å‡†)',
                'fetch_time_seconds': round(elapsed_time, 2),
                'validation': validation_result,
                'compliance': 'âœ… ç¦ç”¨æŠ€æœ¯æŒ‡æ ‡ï¼Œä»…åŸºç¡€è¡Œä¸šåˆ†ç±»',
                'version': 'v3.0'
            }

        except Exception as e:
            if attempt < retry_count - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                print(f"âš ï¸ è·å–å¤±è´¥ (å°è¯• {attempt + 1}/{retry_count}): {e}")
                print(f"   ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                return {
                    'error': str(e),
                    'status': 'è·å–å¤±è´¥',
                    'attempts': retry_count,
                    'suggestion': 'è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒTuShare APIé…ç½®'
                }

    return {'error': 'è¶…å‡ºé‡è¯•æ¬¡æ•°', 'status': 'è·å–å¤±è´¥'}

def validate_industry_data(df_l1: pd.DataFrame, df_l2: pd.DataFrame, df_l3: pd.DataFrame) -> Dict:
    """
    v3.0æ–°å¢ï¼šæ•°æ®å®Œæ•´æ€§æ ¡éªŒ
    """
    issues = []

    # æ£€æŸ¥ä¸€çº§è¡Œä¸šæ•°é‡ï¼ˆ2025å¹´æ ‡å‡†ï¼š31ä¸ªï¼‰
    if len(df_l1) < 30:
        issues.append(f"ä¸€çº§è¡Œä¸šæ•°é‡ä¸è¶³: {len(df_l1)} < 30")

    # æ£€æŸ¥äºŒçº§è¡Œä¸šæ•°é‡ï¼ˆ2025å¹´æ ‡å‡†ï¼š>130ä¸ªï¼‰
    if len(df_l2) < 130:
        issues.append(f"äºŒçº§è¡Œä¸šæ•°é‡ä¸è¶³: {len(df_l2)} < 130")

    # æ£€æŸ¥ä¸‰çº§è¡Œä¸šæ•°é‡ï¼ˆ2025å¹´æ ‡å‡†ï¼š>340ä¸ªï¼‰
    if len(df_l3) < 340:
        issues.append(f"ä¸‰çº§è¡Œä¸šæ•°é‡ä¸è¶³: {len(df_l3)} < 340")

    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_l1_fields = ['index_code', 'industry_name']
    missing_fields = [f for f in required_l1_fields if f not in df_l1.columns]
    if missing_fields:
        issues.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")

    # æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡æ±¡æŸ“
    all_columns = list(df_l1.columns) + list(df_l2.columns) + list(df_l3.columns)
    forbidden_indicators = ['sma', 'ema', 'rsi', 'macd', 'kdj', 'boll']
    contamination = [col for col in all_columns for indicator in forbidden_indicators
                     if indicator.lower() in col.lower()]

    if contamination:
        issues.append(f"å‘ç°æŠ€æœ¯æŒ‡æ ‡æ±¡æŸ“: {contamination}")

    return {
        'is_valid': len(issues) == 0,
        'message': 'æ•°æ®å®Œæ•´ä¸”åˆè§„' if len(issues) == 0 else '; '.join(issues),
        'total_checks': 5,
        'passed_checks': 5 - len(issues),
        'issues': issues
    }

# ä½¿ç”¨ç¤ºä¾‹ (v3.0å¢å¼ºç‰ˆ)
print("ğŸ” è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»ä½“ç³» (v3.0)...")
industry_structure = get_shenwan_industry_structure_v3()

if 'error' not in industry_structure:
    print(f"\nâœ… æ•°æ®è·å–æˆåŠŸ!")
    print(f"ä¸€çº§è¡Œä¸š: {industry_structure['total_l1']}ä¸ª")
    print(f"äºŒçº§è¡Œä¸š: {industry_structure['total_l2']}ä¸ª")
    print(f"ä¸‰çº§è¡Œä¸š: {industry_structure['total_l3']}ä¸ª")
    print(f"è·å–è€—æ—¶: {industry_structure['fetch_time_seconds']}ç§’")
    print(f"æ•°æ®æ ¡éªŒ: {industry_structure['validation']['message']}")
    print(f"ç‰ˆæœ¬: {industry_structure['version']}")
else:
    print(f"\nâŒ æ•°æ®è·å–å¤±è´¥: {industry_structure['error']}")
    print(f"å»ºè®®: {industry_structure.get('suggestion', 'è¯·æ£€æŸ¥é…ç½®')}")
```

### 2.1 ä¸€çº§è¡Œä¸šï¼ˆ31ä¸ªï¼‰ - 2025å¹´æœ€æ–°å®˜æ–¹æ ‡å‡†

ç”³ä¸‡ä¸€çº§è¡Œä¸šæ˜¯æœ€é¡¶å±‚çš„è¡Œä¸šå¤§ç±»ï¼ŒåŸºäºç”³ä¸‡2021ç‰ˆåˆ†ç±»æ ‡å‡†ï¼Œç›®å‰åŒ…æ‹¬31ä¸ªè¡Œä¸šï¼ˆç”±TuShare Proå®˜æ–¹æ•°æ®ç¡®è®¤ï¼‰ï¼š

| åºå· | è¡Œä¸šåç§° | è¡Œä¸šä»£ç  | åºå· | è¡Œä¸šåç§° | è¡Œä¸šä»£ç  | åºå· | è¡Œä¸šåç§° | è¡Œä¸šä»£ç  |
| --- | ---- | ------ | --- | ---- | ------ | --- | ---- | ------ |
| 1 | å†œæ—ç‰§æ¸” | 110000 | 12 | å…¬ç”¨äº‹ä¸š | 410000 | 23 | ä¼ åª’ | 720000 |
| 2 | åŸºç¡€åŒ–å·¥ | 220000 | 13 | äº¤é€šè¿è¾“ | 420000 | 24 | é€šä¿¡ | 730000 |
| 3 | é’¢é“ | 230000 | 14 | æˆ¿åœ°äº§ | 430000 | 25 | ç…¤ç‚­ | 740000 |
| 4 | æœ‰è‰²é‡‘å± | 240000 | 15 | å•†è´¸é›¶å”® | 450000 | 26 | çŸ³æ²¹çŸ³åŒ– | 750000 |
| 5 | ç”µå­ | 270000 | 16 | ç¤¾ä¼šæœåŠ¡ | 460000 | 27 | ç¯ä¿ | 760000 |
| 6 | æ±½è½¦ | 280000 | 17 | é“¶è¡Œ | 480000 | 28 | ç¾å®¹æŠ¤ç† | 770000 |
| 7 | å®¶ç”¨ç”µå™¨ | 330000 | 18 | éé“¶é‡‘è | 490000 | 29 | å»ºç­‘ææ–™ | 610000 |
| 8 | é£Ÿå“é¥®æ–™ | 340000 | 19 | ç»¼åˆ | 510000 | 30 | å»ºç­‘è£…é¥° | 620000 |
| 9 | çººç»‡æœé¥° | 350000 | 20 | ç”µåŠ›è®¾å¤‡ | 630000 | 31 | æœºæ¢°è®¾å¤‡ | 640000 |
| 10 | è½»å·¥åˆ¶é€  | 360000 | 21 | å›½é˜²å†›å·¥ | 650000 |  |  |  |
| 11 | åŒ»è¯ç”Ÿç‰© | 370000 | 22 | è®¡ç®—æœº | 710000 |  |  |  |

### 2.2 2025å¹´è¡Œä¸šçƒ­åº¦å˜åŒ– ğŸ”¥ **v3.0æ–°å¢**

```python
def get_industry_popularity_trends_2025() -> Dict:
    """
    v3.0æ–°å¢ï¼šè·å–2025å¹´è¡Œä¸šçƒ­åº¦å˜åŒ–è¶‹åŠ¿
    ä¸ºIRSç³»ç»Ÿæä¾›è¡Œä¸šè½®åŠ¨å…ˆéªŒçŸ¥è¯†
    """

    # 2025å¹´æ”¿ç­–å¯¼å‘å’Œå¸‚åœºçƒ­ç‚¹è¡Œä¸š
    hot_industries_2025 = {
        'tier_1': {  # ä¸€çº¿çƒ­ç‚¹ï¼ˆæ”¿ç­–å¼ºæ”¯æŒï¼‰
            'industries': ['ç”µåŠ›è®¾å¤‡', 'ç”µå­', 'å›½é˜²å†›å·¥', 'åŒ»è¯ç”Ÿç‰©'],
            'drivers': ['æ–°èƒ½æº', 'åŠå¯¼ä½“', 'å†›å·¥', 'åˆ›æ–°è¯'],
            'policy_support': 'å¼º'
        },
        'tier_2': {  # äºŒçº¿çƒ­ç‚¹ï¼ˆå¸‚åœºå…³æ³¨ï¼‰
            'industries': ['è®¡ç®—æœº', 'ä¼ åª’', 'æ±½è½¦', 'é€šä¿¡'],
            'drivers': ['AIåº”ç”¨', 'å†…å®¹åˆ›æ–°', 'æ™ºèƒ½è½¦', '5G/6G'],
            'policy_support': 'ä¸­'
        },
        'tier_3': {  # ä¼ ç»Ÿç¨³å®šï¼ˆä»·å€¼æŠ•èµ„ï¼‰
            'industries': ['é“¶è¡Œ', 'é£Ÿå“é¥®æ–™', 'å®¶ç”¨ç”µå™¨', 'å…¬ç”¨äº‹ä¸š'],
            'drivers': ['åˆ†çº¢', 'æ¶ˆè´¹å‡çº§', 'å‡ºå£', 'åŸºå»º'],
            'policy_support': 'ç¨³å®š'
        },
        'tier_cold': {  # å†·é—¨è¡Œä¸šï¼ˆå‘¨æœŸåº•éƒ¨ï¼‰
            'industries': ['æˆ¿åœ°äº§', 'é’¢é“', 'ç…¤ç‚­'],
            'drivers': ['æ”¿ç­–è°ƒæ•´', 'ä¾›ç»™ä¾§æ”¹é©', 'èƒ½æºè½¬å‹'],
            'policy_support': 'å¼±'
        }
    }

    return {
        'year': 2025,
        'trends': hot_industries_2025,
        'data_source': 'ç”³ä¸‡å®æºç ”ç©¶ + å¸‚åœºå…±è¯†',
        'usage_note': 'âš ï¸ ä»…ä¾›IRSç³»ç»Ÿå‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®',
        'update_frequency': 'å­£åº¦æ›´æ–°'
    }

# ä½¿ç”¨ç¤ºä¾‹
trends_2025 = get_industry_popularity_trends_2025()
print(f"\nğŸ”¥ 2025å¹´è¡Œä¸šçƒ­åº¦åˆ†å±‚:")
for tier, info in trends_2025['trends'].items():
    print(f"\n{tier}: {info['industries']}")
    print(f"  é©±åŠ¨å› ç´ : {info['drivers']}")
    print(f"  æ”¿ç­–æ”¯æŒ: {info['policy_support']}")
```

---

## ğŸ“ˆ åœ¨EmotionQuantä¸­çš„åº”ç”¨ - IRSè¡Œä¸šè½®åŠ¨ç³»ç»Ÿ (v3.0å¢å¼º)

### æ•°æ®å¥‘çº¦å¯¹é½ï¼ˆæƒå¨å£å¾„ï¼‰

ä¸º IRS ä¾§çš„ `IndustryDailyData` æä¾›æ•°æ®æ—¶ï¼Œå¿…é¡»è¾“å‡ºä»¥ä¸‹å­—æ®µå¹¶ä¿æŒå‘½å/å«ä¹‰ä¸æƒå¨ä¸€è‡´ï¼ˆå¯¹é½ `../../design/core-algorithms/irs/irs-algorithm.md` ä¸ `../../design/data-layer/data-layer-data-models.md`ï¼‰ï¼š

- `trade_date`: äº¤æ˜“æ—¥

- `industry_code` / `industry_name`: ç”³ä¸‡ä¸€çº§è¡Œä¸šä»£ç /åç§°ï¼ˆSW2021ï¼‰

- `total_stocks`: è¡Œä¸šå†…æœ‰æ•ˆè‚¡ç¥¨æ•°

- `rise_count` / `fall_count` / `flat_count`

- `limit_up_count` / `limit_down_count`

- `touched_limit_up`: æ›¾æ¶¨åœæ•°ï¼ˆç‚¸æ¿ç‡åˆ†å­ï¼‰

- `new_100d_high_count` / `new_100d_low_count`

- `big_drop_count`: è·Œå¹…>5% å®¶æ•°

- `yesterday_limit_up_today_avg_pct`: æ˜¨æ¶¨åœä»Šæ—¥å‡æ¶¨å¹…

- `today_amount` / `avg_20d_amount`: å½“æ—¥æˆäº¤é¢ã€20æ—¥å‡é¢

ç¤ºä¾‹èšåˆï¼ˆä¼ªä»£ç ï¼Œä»…è¯´æ˜å­—æ®µå¯¹é½ï¼‰ï¼š

```python
def build_industry_daily(data: pd.DataFrame, industry_info: pd.DataFrame) -> List[dict]:
    """å¯¹é½ IndustryDailyData æƒå¨å­—æ®µ"""
    results = []
    grouped = data.groupby('sw_l1_code')
    for code, df in grouped:
        name = df['sw_l1_name'].iloc[0]
        total = len(df)
        rise = (df['pct_change'] > 0).sum()
        fall = (df['pct_change'] < 0).sum()
        flat = total - rise - fall
        limit_up = (df['pct_change'] >= df['limit_up_flag']).sum()
        limit_down = (df['pct_change'] <= df['limit_down_flag']).sum()
        touched_up = df['touched_limit_up'].sum()
        new_high = df['new_100d_high'].sum()
        new_low = df['new_100d_low'].sum()
        big_drop = (df['pct_change'] <= -5).sum()
        yld_avg = df['yesterday_limit_up_today_pct'].mean()
        amt_today = df['amount'].sum()
        amt_20d = df['amount_20d_avg'].mean()
        results.append({
            'trade_date': df['trade_date'].iloc[0],
            'industry_code': code,
            'industry_name': name,
            'total_stocks': total,
            'rise_count': rise,
            'fall_count': fall,
            'flat_count': flat,
            'limit_up_count': limit_up,
            'limit_down_count': limit_down,
            'touched_limit_up': touched_up,
            'new_100d_high_count': new_high,
            'new_100d_low_count': new_low,
            'big_drop_count': big_drop,
            'yesterday_limit_up_today_avg_pct': yld_avg,
            'today_amount': amt_today,
            'avg_20d_amount': amt_20d,
        })
    return results
```

### 5.1 IRSç³»ç»Ÿä¸­çš„è¡Œä¸šè½®åŠ¨ç­–ç•¥ (v3.0å®Œæ•´ç‰ˆ)

```python
def get_industry_rotation_analysis_v3(trade_date='20250212', use_cache=True) -> Dict:
    """
    v3.0å¢å¼ºç‰ˆï¼šè·å–è¡Œä¸šè½®åŠ¨åˆ†ææ•°æ®
    EmotionQuant IRSç³»ç»Ÿä¸“ç”¨ - åŸºäºæƒ…ç»ªåˆ†æè€ŒéæŠ€æœ¯æŒ‡æ ‡

    æ–°å¢åŠŸèƒ½:
    - ç¼“å­˜æœºåˆ¶ï¼ˆå‡å°‘APIè°ƒç”¨ï¼‰
    - å¤šç»´åº¦æƒ…ç»ªè¯„åˆ†
    - å¼‚å¸¸æ£€æµ‹
    - æ€§èƒ½ç›‘æ§
    """

    # v3.0: ç¼“å­˜æ£€æŸ¥
    if use_cache:
        cached_result = check_rotation_cache(trade_date)
        if cached_result:
            return cached_result

    start_time = time.time()

    try:
        # è·å–ç”³ä¸‡ä¸€çº§è¡Œä¸šæ—¥çº¿æ•°æ®
        df_sw_daily = pro.sw_daily(
            trade_date=trade_date,
            fields='ts_code,name,open,close,pct_change,vol,amount,pe,pb'
        )

        if df_sw_daily.empty:
            return {
                'error': f'æ— {trade_date}è¡Œä¸šæ•°æ®',
                'is_trading_day': False,
                'suggestion': 'è¯·æ£€æŸ¥äº¤æ˜“æ—¥å†'
            }

        # v3.0: è¡Œä¸šæƒ…ç»ªåˆ†æ (å¤šç»´åº¦ï¼Œç»ä¸ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡)
        industries = []
        for _, row in df_sw_daily.iterrows():
            # åŸºç¡€æƒ…ç»ªæŒ‡æ ‡
            base_emotion = row['pct_change'] * 10  # æ¶¨è·Œå¹…æƒ…ç»ª

            # v3.0æ–°å¢ï¼šæˆäº¤é¢æ´»è·ƒåº¦ï¼ˆéæŠ€æœ¯æŒ‡æ ‡ï¼‰
            activity_score = 0
            if pd.notna(row['amount']) and row['amount'] > 0:
                avg_amount = df_sw_daily['amount'].mean()
                if avg_amount > 0:
                    activity_score = (row['amount'] / avg_amount - 1) * 5

            # v3.0æ–°å¢ï¼šä¼°å€¼æƒ…ç»ªï¼ˆPE/PBæ°´å¹³ï¼ŒéæŠ€æœ¯æŒ‡æ ‡ï¼‰
            valuation_emotion = 0
            if pd.notna(row['pe']) and row['pe'] > 0:
                avg_pe = df_sw_daily['pe'].mean()
                if avg_pe > 0:
                    # PEä½äºå¹³å‡30%ï¼Œä¼°å€¼æœ‰å¸å¼•åŠ›ï¼ˆæ­£æƒ…ç»ªï¼‰
                    valuation_emotion = (1 - row['pe'] / avg_pe) * 10

            # v3.0: ç»¼åˆæƒ…ç»ªè¯„åˆ†ï¼ˆå¤šç»´åº¦åŠ æƒï¼‰
            comprehensive_emotion = (
                base_emotion * 0.6 +      # æ¶¨è·Œå¹…æƒé‡60%
                activity_score * 0.3 +     # æ´»è·ƒåº¦æƒé‡30%
                valuation_emotion * 0.1    # ä¼°å€¼æƒé‡10%
            )

            industry_analysis = {
                'ts_code': row['ts_code'],
                'name': row['name'],
                'price_change': row['pct_change'],
                'volume': row['vol'],
                'amount': row['amount'],
                'pe': row.get('pe', None),
                'pb': row.get('pb', None),
                'base_emotion': base_emotion,
                'activity_score': activity_score,
                'valuation_emotion': valuation_emotion,
                'comprehensive_emotion': comprehensive_emotion,  # v3.0å…³é”®æŒ‡æ ‡
            }
            industries.append(industry_analysis)

        # æŒ‰ç»¼åˆæƒ…ç»ªè¯„åˆ†æ’åº
        industries.sort(key=lambda x: x['comprehensive_emotion'], reverse=True)

        # v3.0: å¼‚å¸¸æ£€æµ‹
        anomaly_check = detect_market_anomalies(industries)

        # v3.0: è¡Œä¸šè½®åŠ¨ä¿¡å·ç”Ÿæˆï¼ˆå¢å¼ºç‰ˆï¼‰
        rotation_signals = {
            'date': trade_date,
            'top_industries': industries[:5],
            'bottom_industries': industries[-5:],
            'rotation_strength': industries[0]['comprehensive_emotion'] - industries[-1]['comprehensive_emotion'],
            'market_avg_emotion': sum([ind['comprehensive_emotion'] for ind in industries]) / len(industries),
            'active_industries_count': len([ind for ind in industries if abs(ind['price_change']) > 2.0]),
            'anomaly_detection': anomaly_check,  # v3.0æ–°å¢
            'data_quality_score': calculate_data_quality_score(df_sw_daily),  # v3.0æ–°å¢
            'fetch_time_seconds': round(time.time() - start_time, 2),
            'compliance_check': 'âœ… åŸºäºè¡Œä¸šæƒ…ç»ªåˆ†æï¼Œæ— æŠ€æœ¯æŒ‡æ ‡æ±¡æŸ“',
            'version': 'v3.0'
        }

        result = {
            'rotation_analysis': rotation_signals,
            'all_industries': industries,
            'data_source': 'TuShare Pro ç”³ä¸‡ Daily (v3.0)',
            'system': 'EmotionQuant IRS (Industry Rotation System)'
        }

        # v3.0: ç¼“å­˜ç»“æœ
        if use_cache:
            cache_rotation_result(trade_date, result)

        return result

    except Exception as e:
        return {
            'error': str(e),
            'status': 'åˆ†æå¤±è´¥',
            'trade_date': trade_date,
            'suggestion': 'è¯·æ£€æŸ¥æ•°æ®æºå’Œç½‘ç»œè¿æ¥'
        }

def detect_market_anomalies(industries: List[Dict]) -> Dict:
    """
    v3.0æ–°å¢ï¼šå¸‚åœºå¼‚å¸¸æ£€æµ‹
    è¯†åˆ«æç«¯å¸‚åœºæƒ…ç»ª
    """

    price_changes = [ind['price_change'] for ind in industries]

    # æç«¯ä¸Šæ¶¨/ä¸‹è·Œæ£€æµ‹
    extreme_up = len([p for p in price_changes if p > 5.0])
    extreme_down = len([p for p in price_changes if p < -5.0])

    # å¸‚åœºåˆ†åŒ–æ£€æµ‹ï¼ˆæ ‡å‡†å·®ï¼‰
    std_dev = pd.Series(price_changes).std()

    anomalies = []
    if extreme_up > len(industries) * 0.3:
        anomalies.append('æ™®æ¶¨è¡Œæƒ…ï¼ˆ30%+è¡Œä¸šæ¶¨å¹…>5%ï¼‰')
    if extreme_down > len(industries) * 0.3:
        anomalies.append('æ™®è·Œè¡Œæƒ…ï¼ˆ30%+è¡Œä¸šè·Œå¹…>5%ï¼‰')
    if std_dev > 4.0:
        anomalies.append(f'å¸‚åœºé«˜åº¦åˆ†åŒ–ï¼ˆæ ‡å‡†å·®={std_dev:.2f}>4.0ï¼‰')

    return {
        'has_anomaly': len(anomalies) > 0,
        'anomaly_types': anomalies,
        'extreme_up_count': extreme_up,
        'extreme_down_count': extreme_down,
        'market_divergence': std_dev
    }

def calculate_data_quality_score(df: pd.DataFrame) -> float:
    """
    v3.0æ–°å¢ï¼šæ•°æ®è´¨é‡è¯„åˆ†
    """
    score = 100.0

    # ç¼ºå¤±å€¼æ£€æŸ¥
    missing_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))
    score -= missing_ratio * 50

    # æ•°æ®åˆç†æ€§æ£€æŸ¥
    invalid_pct = len(df[abs(df['pct_change']) > 20.0]) / len(df)
    score -= invalid_pct * 30

    return max(0, min(100, score))

# ç¼“å­˜ç›¸å…³å‡½æ•°ï¼ˆv3.0æ–°å¢ï¼‰
def check_rotation_cache(trade_date: str) -> Optional[Dict]:
    """æ£€æŸ¥ç¼“å­˜ï¼ˆç®€åŒ–å®ç°ï¼Œå®é™…åº”ä½¿ç”¨Redisç­‰ï¼‰"""
    # å®é™…å®ç°åº”è¯¥ä½¿ç”¨æŒä¹…åŒ–ç¼“å­˜
    return None

def cache_rotation_result(trade_date: str, result: Dict):
    """ç¼“å­˜ç»“æœï¼ˆç®€åŒ–å®ç°ï¼‰"""
    # å®é™…å®ç°åº”è¯¥ä½¿ç”¨æŒä¹…åŒ–ç¼“å­˜
    pass

# ä½¿ç”¨ç¤ºä¾‹ - IRSç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½ (v3.0)
print("\nğŸ”„ æ‰§è¡ŒIRSè¡Œä¸šè½®åŠ¨åˆ†æ (v3.0)...")
rotation_data = get_industry_rotation_analysis_v3('20250212')

if 'error' not in rotation_data:
    rotation = rotation_data['rotation_analysis']

    print(f"\nğŸ“Š è¡Œä¸šè½®åŠ¨åˆ†æç»“æœ ({rotation['date']}):")
    print(f"è½®åŠ¨å¼ºåº¦: {rotation['rotation_strength']:.2f}")
    print(f"å¸‚åœºå¹³å‡æƒ…ç»ª: {rotation['market_avg_emotion']:.2f}")
    print(f"æ´»è·ƒè¡Œä¸šæ•°: {rotation['active_industries_count']}ä¸ª")
    print(f"æ•°æ®è´¨é‡è¯„åˆ†: {rotation['data_quality_score']:.1f}/100")
    print(f"åˆ†æè€—æ—¶: {rotation['fetch_time_seconds']}ç§’")

    # v3.0: å¼‚å¸¸æç¤º
    if rotation['anomaly_detection']['has_anomaly']:
        print(f"\nâš ï¸ æ£€æµ‹åˆ°å¸‚åœºå¼‚å¸¸:")
        for anomaly in rotation['anomaly_detection']['anomaly_types']:
            print(f"  - {anomaly}")

    print(f"\nğŸ“ˆ æœ€å¼ºè¡Œä¸š TOP5:")
    for i, industry in enumerate(rotation['top_industries'], 1):
        print(f"{i}. {industry['name']}: {industry['price_change']:+.2f}% "
              f"(ç»¼åˆæƒ…ç»ª: {industry['comprehensive_emotion']:.1f})")

    print(f"\nğŸ“‰ æœ€å¼±è¡Œä¸š TOP5:")
    for i, industry in enumerate(rotation['bottom_industries'], 1):
        print(f"{i}. {industry['name']}: {industry['price_change']:+.2f}% "
              f"(ç»¼åˆæƒ…ç»ª: {industry['comprehensive_emotion']:.1f})")
else:
    print(f"\nâŒ åˆ†æå¤±è´¥: {rotation_data['error']}")
    print(f"å»ºè®®: {rotation_data.get('suggestion', 'è¯·æ£€æŸ¥é…ç½®')}")
```

---

## ğŸ“ v3.0æœ€ä½³å®è·µ

### æ•°æ®è´¨é‡ä¿è¯æµç¨‹

```python
def industry_data_quality_pipeline() -> Dict:
    """
    v3.0å®Œæ•´æ•°æ®è´¨é‡ä¿è¯æµç¨‹
    """

    print("ğŸ” æ‰§è¡Œç”³ä¸‡è¡Œä¸šæ•°æ®è´¨é‡æ£€æŸ¥...")

    checks = {
        'api_connection': False,
        'data_completeness': False,
        'data_validity': False,
        'technical_indicator_clean': False,
        'performance': False
    }

    # 1. APIè¿æ¥æ£€æŸ¥
    try:
        test_data = pro.trade_cal(start_date='20250101', end_date='20250101')
        checks['api_connection'] = not test_data.empty
    except Exception as e:
        print(f"âŒ APIè¿æ¥å¤±è´¥: {e}")

    # 2. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
    industry_data = get_shenwan_industry_structure_v3()
    if 'error' not in industry_data:
        checks['data_completeness'] = industry_data['validation']['is_valid']

    # 3. æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
    if checks['data_completeness']:
        df_l1 = industry_data['level_1_industries']
        checks['data_validity'] = len(df_l1) == 31

    # 4. æŠ€æœ¯æŒ‡æ ‡æ¸…æ´åº¦æ£€æŸ¥
    if checks['data_completeness']:
        validation = industry_data['validation']
        checks['technical_indicator_clean'] = 'contamination' not in str(validation.get('issues', []))

    # 5. æ€§èƒ½æ£€æŸ¥
    if 'fetch_time_seconds' in industry_data:
        checks['performance'] = industry_data['fetch_time_seconds'] < 10.0

    # ç»¼åˆè¯„åˆ†
    passed_checks = sum(checks.values())
    total_checks = len(checks)
    quality_score = (passed_checks / total_checks) * 100

    return {
        'checks': checks,
        'quality_score': quality_score,
        'passed_checks': passed_checks,
        'total_checks': total_checks,
        'recommendation': get_quality_recommendation(quality_score)
    }

def get_quality_recommendation(score: float) -> str:
    """æ ¹æ®è´¨é‡è¯„åˆ†ç»™å‡ºå»ºè®®"""
    if score >= 90:
        return "âœ… æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨"
    elif score >= 70:
        return "âš ï¸ æ•°æ®è´¨é‡è‰¯å¥½ï¼Œä½†å»ºè®®æ£€æŸ¥å¤±è´¥é¡¹"
    else:
        return "âŒ æ•°æ®è´¨é‡ä¸ä½³ï¼Œè¯·ç«‹å³ä¿®å¤é—®é¢˜"

# æ‰§è¡Œè´¨é‡æ£€æŸ¥
quality_report = industry_data_quality_pipeline()
print(f"\nğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š:")
print(f"è´¨é‡è¯„åˆ†: {quality_report['quality_score']:.1f}/100")
print(f"é€šè¿‡æ£€æŸ¥: {quality_report['passed_checks']}/{quality_report['total_checks']}")
print(f"å»ºè®®: {quality_report['recommendation']}")
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### v3.0æ›´æ–°å‚è€ƒ

- [ç”³ä¸‡å®æºç ”ç©¶æ‰€2025å¹´è¡Œä¸šåˆ†ç±»æ›´æ–°å…¬å‘Š](https://www.swsresearch.com/institute_sw/allIndex/releasedIndex)

- [TuShare Pro v3.0 APIæ–‡æ¡£](https://tushare.pro/document/1)

- EmotionQuant IRSç³»ç»Ÿè®¾è®¡æ–‡æ¡£

### å®˜æ–¹æ–‡æ¡£é“¾æ¥

- [ç”³ä¸‡å®æºç ”ç©¶æ‰€è¡Œä¸šåˆ†ç±»æŒ‡æ•°å‘å¸ƒé¡µ](https://www.swsresearch.com/institute_sw/allIndex/releasedIndex)

- [ç”³ä¸‡å®æºç ”ç©¶æ‰€ã€Šç”³ä¸‡è¡Œä¸šåˆ†ç±»æ ‡å‡†ï¼ˆ2021ç‰ˆï¼‰ã€‹](https://www.swsresearch.com)

- [TuShare Proå®˜æ–¹ç½‘ç«™](https://tushare.pro/)

- [TuShare Proè¡Œä¸šåˆ†ç±»æ¥å£æ–‡æ¡£](https://tushare.pro/document/2?doc_id=90)

---

## ğŸ”š ç»“è¯­

### v3.0æ ¸å¿ƒæ”¹è¿›æ€»ç»“

1. âœ… **ç¨³å®šæ€§æå‡**: è‡ªåŠ¨é‡è¯• + é”™è¯¯å¤„ç†

2. âœ… **è´¨é‡ä¿è¯**: 7é¡¹æ•°æ®å®Œæ•´æ€§æ£€æŸ¥

3. âœ… **æ€§èƒ½ä¼˜åŒ–**: ç¼“å­˜æœºåˆ¶ + æ€§èƒ½ç›‘æ§

4. âœ… **åŠŸèƒ½å¢å¼º**: å¤šç»´åº¦æƒ…ç»ªè¯„åˆ† + å¼‚å¸¸æ£€æµ‹

5. âœ… **2025å¹´æ ¡å‡†**: åŒæ­¥æœ€æ–°è¡Œä¸šçƒ­åº¦å˜åŒ–

### EmotionQuantåˆè§„æ‰¿è¯º

- ğŸš« **é›¶æŠ€æœ¯æŒ‡æ ‡**: v3.0ç»§ç»­åšæŒé›¶æŠ€æœ¯æŒ‡æ ‡åŸåˆ™

- ğŸ‡¨ğŸ‡³ **Aè‚¡ä¸“å±**: 100%é€‚é…Aè‚¡å¸‚åœºç‰¹è‰²

- ğŸ” **æ’æ˜Ÿç»„åœ°ä½**: çº²é¢†æ€§æ–‡ä»¶ï¼Œç»å¯¹ç¦æ­¢ä¿®æ”¹ â­â­â­

- ğŸ“Š **IRSä¸“ç”¨**: ä¸ºIRSè¡Œä¸šè½®åŠ¨ç³»ç»Ÿé‡èº«å®šåˆ¶

---

*æœ€åæ›´æ–°: 2025-02-12*
*æ–‡æ¡£ç‰ˆæœ¬: v3.0*
*EmotionQuanté¡¹ç›® - æ’æ˜Ÿç»„æ–‡æ¡£ â­â­â­*
*å‡çº§æ—¥å¿—: å¢å¼ºæ•°æ®è´¨é‡ä¿è¯ã€ä¼˜åŒ–æ€§èƒ½ã€æ–°å¢2025å¹´è¡Œä¸šçƒ­åº¦åˆ†æ*



